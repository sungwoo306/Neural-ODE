{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 From Python lists to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paul/opt/miniconda3/envs/qtc/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = [1.0, 2.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]\n",
    "a[2] = 3.0\n",
    "a[2]\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing our first tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.0\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 The essence of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(6)\n",
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0\n",
    "points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0,1.0],[5.0,3.0],[2.0,1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(3,2)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0,1.0],[5.0,3.0],[2.0,1.0]])\n",
    "points[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Indexing Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list = list(range(6))\n",
    "some_list[:]\n",
    "some_list[1:4]\n",
    "some_list[1:]\n",
    "some_list[:-1]\n",
    "some_list[1:4:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:]\n",
    "points[1:,:]\n",
    "points[1:,0]\n",
    "points[None] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Named tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7938,  0.6075,  0.9082,  0.4241,  2.2572],\n",
       "         [-0.8217,  0.4987, -0.0948,  1.0067, -0.4655],\n",
       "         [ 0.3190,  1.0046, -0.5981, -0.1966,  1.5389],\n",
       "         [ 0.2672,  0.5282, -1.6886,  0.3451, -1.1807],\n",
       "         [ 0.2916,  1.1839, -1.4662,  1.1264, -1.1599]],\n",
       "\n",
       "        [[-0.1817, -0.2853,  0.1442, -0.9643,  1.0890],\n",
       "         [ 0.4344,  0.2009,  0.5308, -0.9848, -1.3542],\n",
       "         [ 1.0477,  1.2237, -0.5820,  1.2197,  0.9340],\n",
       "         [ 0.6360, -1.1807,  1.0356,  0.2587,  0.0816],\n",
       "         [-0.5641,  0.1976, -1.2551,  1.9304, -2.3320]],\n",
       "\n",
       "        [[ 0.2006, -1.7610, -0.1867, -1.4708,  1.2231],\n",
       "         [-0.5939,  1.5249, -0.3881,  1.4355,  0.1178],\n",
       "         [-0.4833, -0.7895, -0.0149, -0.9326,  1.2126],\n",
       "         [-0.4570, -0.4582, -2.2897,  1.5273, -1.3202],\n",
       "         [-0.7859,  0.1795, -0.3935,  0.2754, -2.5857]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.randn(3,5,5) # shape [channels, rows, columns]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3) # ()안에 숫자는 .size()의 Index위치를 나타냄. negative indexing이 가능함. 보통은 -1만 씀.\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 5]) torch.Size([3]) torch.Size([3, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]),\n",
       " torch.Size([2, 3, 5, 5]),\n",
       " torch.Size([3, 1, 1]),\n",
       " torch.Size([3, 5, 5]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "img_weights = (img_t*unsqueezed_weights)\n",
    "batch_weights = (batch_t*unsqueezed_weights)\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "print(img_t.shape, weights.shape, unsqueezed_weights.shape)\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape, img_weights.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unsqueeze example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "b = torch.tensor([1, 1])\n",
    "print(a.size(), b.size())\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/paul/Desktop/JHElab/Project/Neural ODE/Book_Test.ipynb 셀 28\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paul/Desktop/JHElab/Project/Neural%20ODE/Book_Test.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paul/Desktop/JHElab/Project/Neural%20ODE/Book_Test.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(a\u001b[39m.\u001b[39msize(), b\u001b[39m.\u001b[39msize())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/paul/Desktop/JHElab/Project/Neural%20ODE/Book_Test.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m a\u001b[39m+\u001b[39;49mb\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 3, 5], [2, 4, 6]])\n",
    "b = torch.tensor([1, 1])\n",
    "print(a.size(), b.size())\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [1]])\n",
      "torch.Size([2, 3]) torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4, 6],\n",
       "        [3, 5, 7]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 3, 5], [2, 4, 6]])\n",
    "b = torch.tensor([1, 1]).unsqueeze(-1)\n",
    "print(b)\n",
    "print(a.size(), b.size())\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 5]) torch.Size([3]) torch.Size([2, 3, 5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.3845, -1.1025,  0.5564,  0.5431, -0.1063],\n",
       "           [-0.6325,  0.4164, -0.4063,  0.4241,  0.7437],\n",
       "           [ 0.0489, -0.7385,  1.4587,  0.7679,  1.0362],\n",
       "           [-0.1793, -1.9656,  0.1711,  1.8167,  0.4754],\n",
       "           [ 1.3298, -0.5517, -1.0594, -1.4008, -1.1963]],\n",
       " \n",
       "          [[-1.0382, -1.3235,  0.6334,  0.0487, -1.4143],\n",
       "           [ 1.4939,  0.1094, -0.3771,  1.0141, -0.2653],\n",
       "           [-0.8385, -2.7776,  0.3090,  0.5571, -1.1236],\n",
       "           [ 1.1892,  1.1327, -1.3428,  0.7328, -0.1831],\n",
       "           [-1.6401, -1.0479, -0.4189, -1.4258,  0.7155]],\n",
       " \n",
       "          [[-1.5731, -0.7965,  1.5081,  0.1891, -1.4752],\n",
       "           [-0.2894, -0.2603, -0.3767, -0.6214, -0.7118],\n",
       "           [ 0.7494,  0.4127, -1.6566,  0.0103,  0.0305],\n",
       "           [-0.3892,  0.0955,  0.7855, -0.6072,  0.7304],\n",
       "           [-1.4054, -1.0455, -2.1222, -0.7565,  0.3038]]],\n",
       " \n",
       " \n",
       "         [[[-2.7866,  0.9065,  0.8948,  0.2816,  1.3638],\n",
       "           [-1.7164,  1.7750, -0.0635,  0.4487, -0.7344],\n",
       "           [-1.2452,  0.7661,  0.1486, -0.6109,  0.0123],\n",
       "           [-0.2887,  1.7772,  0.2166, -0.2693,  0.9249],\n",
       "           [ 0.1268, -0.2446, -0.3592, -1.7454, -0.4352]],\n",
       " \n",
       "          [[-1.6933,  0.6844, -1.9183, -0.1707,  0.4175],\n",
       "           [ 0.2154, -1.7301, -0.0872, -0.1196, -1.9897],\n",
       "           [ 2.1381, -0.2206,  1.6686,  0.0415,  0.9537],\n",
       "           [ 1.9222, -0.6415,  0.1851, -1.0309,  0.9509],\n",
       "           [-0.2828,  0.2324,  0.3125, -2.5966, -0.4121]],\n",
       " \n",
       "          [[-2.0620, -1.1809,  0.3991, -2.1283, -0.5026],\n",
       "           [ 0.8593, -1.0017,  1.8555,  0.5059, -0.9065],\n",
       "           [-0.0903, -0.3182, -0.9221,  0.5156, -0.3002],\n",
       "           [-0.1414, -1.2098, -0.3300, -1.0081, -1.5491],\n",
       "           [ 0.5550, -1.3389, -0.9087,  0.1141,  0.3195]]]]),\n",
       " tensor([0.2126, 0.7152, 0.0722]),\n",
       " tensor([[[-0.7743, -1.2385,  0.6802,  0.1639, -1.1406],\n",
       "          [ 0.9131,  0.1480, -0.3833,  0.7706, -0.0830],\n",
       "          [-0.5352, -2.1138,  0.4115,  0.5624, -0.5811],\n",
       "          [ 0.7843,  0.3991, -0.8673,  0.8665,  0.0229],\n",
       "          [-0.9918, -0.9422, -0.6780, -1.3722,  0.2793]],\n",
       " \n",
       "         [[-1.9524,  0.5970, -1.1529, -0.2159,  0.5523],\n",
       "          [-0.1488, -0.9323,  0.0581,  0.0464, -1.6446],\n",
       "          [ 1.2579, -0.0179,  1.1584, -0.0629,  0.6630],\n",
       "          [ 1.3032, -0.1683,  0.1546, -0.8673,  0.7649],\n",
       "          [-0.1352,  0.0175,  0.0815, -2.2199, -0.3642]]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(img_t.shape, weights.shape, batch_t.shape)\n",
    "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
    "batch_t, weights, batch_gray_weighted_fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named:  torch.Size([3, 5, 5]) ('channels', 'rows', 'column')\n",
      "batch named:  torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'column')\n"
     ]
    }
   ],
   "source": [
    "img_named = img_t.refine_names(...,'channels','rows','column')\n",
    "batch_named = batch_t.refine_names(...,'channels','rows','column')\n",
    "print(\"img named: \", img_named.shape, img_named.names)\n",
    "print(\"batch named: \", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]), ('channels', 'rows', 'column'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)\n",
    "weights_aligned.shape, weights_aligned.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'column'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error when attempting to broadcast dims ['channels', 'rows', 'column'] and dims ['channels']: dim 'column' and dim 'channels' are at the same position from the right but do not match.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/paul/Desktop/JHElab/Project/Neural ODE/Book_Test.ipynb 셀 35\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/paul/Desktop/JHElab/Project/Neural%20ODE/Book_Test.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gray_named \u001b[39m=\u001b[39m (img_named[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, :\u001b[39m3\u001b[39;49m]\u001b[39m*\u001b[39;49mweights_named)\u001b[39m.\u001b[39msum(\u001b[39m'\u001b[39m\u001b[39mchannels\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error when attempting to broadcast dims ['channels', 'rows', 'column'] and dims ['channels']: dim 'column' and dim 'channels' are at the same position from the right but do not match."
     ]
    }
   ],
   "source": [
    "gray_named = (img_named[..., :3]*weights_named).sum('channels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), (None, None))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.3 Managing a tensor's dtype attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.zeros(10,2).double()\n",
    "short_points = torch.ones(10,2).short()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.zeros(10,2).to(torch.double)\n",
    "short_points = torch.ones(10,2).to(dtype=torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_64 = torch.rand(5, dtype=torch.double)\n",
    "points_short = points_64.to(torch.short)\n",
    "points_64 * points_short # works form PyTorch 1.3 onwards"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 The tensor API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,2)\n",
    "a_t = torch.transpose(a, 0, 1)\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,2)\n",
    "a_t = a.transpose(0,1)\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.1 Indexing into storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0,1.0],[5.0,3.0],[2.0,1.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_storage = points.storage()\n",
    "points_storage[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0,1.0],[5.0,3.0],[2.0,1.0]])\n",
    "points_storage = points.storage()\n",
    "points_storage[0] = 2.0\n",
    "points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.2 Modifying stored values : In-place operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,2)\n",
    "a.zero_()\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 Tensor metadata : Size, offset, and stride"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1 Views of another tensor's storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1] # points.storage를 그대로 가져와서 offset이 바뀜\n",
    "second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point = points[1]\n",
    "second_point.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1] # points.storage를 그대로 가져와서 offset이 바뀜\n",
    "second_point[0] = 10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1].clone()\n",
    "second_point = 10.0\n",
    "points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.2 Transposing without copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(points.storage()) == id(points_t.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.3 Transposing in higher dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t = torch.ones(3, 4, 5)\n",
    "transpose_t = some_t.transpose(0, 2)\n",
    "some_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 3])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 20)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.stride()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.4 Contiguous tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont = points_t.contiguous()\n",
    "points_t_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 5.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e34661f62bd8e945851969cf164be387ceff78bd554b7a7643e0a350d74b779"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
